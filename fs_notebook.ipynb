{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Found on [Kaggle](https://www.kaggle.com/rounakbanik/the-movies-dataset), collected from [TMDB](https://www.themoviedb.org/?language=en) and [GroupLens](https://grouplens.org/datasets/movielens/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
       "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
       "       'vote_average', 'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Start importing some of the features available\n",
    "df = pd.read_csv('data/movies_metadata.csv',dtype={'original_language': 'str','poster_path': 'str'},low_memory=False)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Have a look at some of the data\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approx 45k movies with 24 features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some cleanup\n",
    "\n",
    "Largely taken from [this notebook](https://www.kaggle.com/rounakbanik/the-story-of-film) accompanying dataset on [Kaggle](https://www.kaggle.com/rounakbanik/the-movies-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')\n",
    "df['revenue'] = df['revenue'].replace(0, np.nan)\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
    "df['budget'] = df['budget'].replace(0, np.nan)\n",
    "df = df.drop(['original_title'], axis=1)\n",
    "df = df.drop(['poster_path'], axis=1)\n",
    "df = df.drop('adult', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new feature -- percent profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40085, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['return'] = df['revenue'] / df['budget']\n",
    "df['budget'] = df['budget'].replace(0, np.nan)\n",
    "df[df['return'].isnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the json stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features related to reception of film online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['popularity'] = df['popularity'].apply(clean_numeric).astype('float')\n",
    "df['vote_count'] = df['vote_count'].apply(clean_numeric).astype('float')\n",
    "df['vote_average'] = df['vote_average'].apply(clean_numeric).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add credits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('data/credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits['id'] = credits['id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove some buggy data, luckily not needed for this tournament\n",
    "df=df[df['id']!='1997-08-20']#bug in data?\n",
    "df=df[df['id']!='2012-09-29']#bug in data?\n",
    "df=df[df['id']!='2014-01-01']#bug in data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits['id'] = credits['id'].astype('int')\n",
    "df['id'] = df['id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(credits, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45538, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cast_size'] = df['cast'].apply(lambda x: len(x))\n",
    "df['crew_size'] = df['crew'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all but the features we'll want later and some final cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=df[['id','title','year','return','budget','runtime','cast_size','crew_size','popularity','vote_count', 'vote_average']]\n",
    "\n",
    "#Remove NaN\n",
    "md = md.fillna(-1) #replace NaN with -1\n",
    "\n",
    "#Normalize the numbers, except year.  do that one later.\n",
    "md[['return','budget','runtime','cast_size','crew_size','popularity','vote_count', 'vote_average']] = minmax_scale(md[['return','budget','runtime','cast_size','crew_size','popularity','vote_count', 'vote_average']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45538, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Filmspotting Madness Bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_match(md, title1, title2, title1win):\n",
    "    df1=md[(md['title']==title1) & (md['year'] > 1989) & (md['year'] < 2000)]\n",
    "    df1 = df1.add_suffix('_1')\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "\n",
    "    df2=md[(md['title']==title2) & (md['year'] > 1989) & (md['year'] < 2000)]\n",
    "    df2 = df2.add_suffix('_2')\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "    my_match=df1.join(df2)\n",
    "\n",
    "    my_match['title_1_wins']=title1win\n",
    "        \n",
    "    return my_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round 1\n",
    "my_match = make_match(md, \"Pulp Fiction\", \"Wild at Heart\", 1)\n",
    "my_match = my_match.append( make_match(md, \"Saving Private Ryan\", \"Out of Sight\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Toy Story\", \"The Sixth Sense\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Schindler's List\", \"The Iron Giant\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fight Club\", \"Safe\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Barton Fink\", \"Leon: The Professional\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Chungking Express\", \"My Own Private Idaho\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Jackie Brown\", \"Princess Mononoke\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Silence of the Lambs\",\"Close-Up\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Terminator 2: Judgment Day\", \"The Lion King\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Heat\", \"JFK\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Dazed and Confused\", \"The Player\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Boogie Nights\", \"Naked\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Malcolm X\", \"Blue\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Big Lebowski\", \"The Truman Show\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Groundhog Day\", \"Edward Scissorhands\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"GoodFellas\", \"There's Something About Mary\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Jurassic Park\", \"Miller's Crossing\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Magnolia\", \"All About My Mother\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Being John Malkovich\", \"Office Space\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Unforgiven\", \"Metropolitan\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Trainspotting\", \"Clueless\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Matrix\", \"The Blair Witch Project\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Hoop Dreams\", \"The Thin Red Line\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fargo\", \"Dead Man\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"L.A. Confidential\", \"Glengarry Glen Ross\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Before Sunrise\", \"The Insider\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Eyes Wide Shut\", \"The Piano\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Rushmore\", \"The Sweet Hereafter\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Shawshank Redemption\", \"The Usual Suspects\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Reservoir Dogs\", \"Boyz n the Hood\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Se7en\", \"Starship Troopers\", 1) )\n",
    "\n",
    "#Round 2\n",
    "my_match = my_match.append( make_match(md, \"Pulp Fiction\", \"Saving Private Ryan\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Toy Story\", \"Schindler's List\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fight Club\", \"Barton Fink\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Jackie Brown\", \"Chungking Express\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Silence of the Lambs\", \"Terminator 2: Judgment Day\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Dazed and Confused\", \"Heat\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Boogie Nights\", \"Malcolm X\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Big Lebowski\", \"Groundhog Day\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"GoodFellas\", \"Jurassic Park\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Magnolia\", \"Being John Malkovich\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Unforgiven\", \"Trainspotting\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Matrix\", \"Hoop Dreams\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fargo\", \"L.A. Confidential\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Before Sunrise\", \"Eyes Wide Shut\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Rushmore\", \"The Shawshank Redemption\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Reservoir Dogs\", \"Se7en\", 1) )\n",
    "\n",
    "#Round 3\n",
    "my_match = my_match.append( make_match(md, \"Pulp Fiction\", \"Toy Story\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fight Club\", \"Jackie Brown\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Silence of the Lambs\", \"Dazed and Confused\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Big Lebowski\", \"Boogie Nights\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"GoodFellas\", \"Being John Malkovich\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Matrix\", \"Unforgiven\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fargo\", \"Before Sunrise\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Rushmore\", \"Se7en\", 1) )\n",
    "\n",
    "#Round 4\n",
    "my_match = my_match.append( make_match(md, \"Pulp Fiction\", \"Fight Club\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"The Silence of the Lambs\", \"The Big Lebowski\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"GoodFellas\", \"The Matrix\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fargo\", \"Rushmore\", 1) )\n",
    "\n",
    "#Round 5\n",
    "my_match = my_match.append( make_match(md, \"Pulp Fiction\", \"The Silence of the Lambs\", 1) )\n",
    "my_match = my_match.append( make_match(md, \"Fargo\", \"GoodFellas\", 1) )\n",
    "\n",
    "\n",
    "#Have a look\n",
    "#my_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add same matches with movies in reverse order so NN doesn't learn preference for arbitrary movie number ordering\n",
    "NB: we remove duplicates between training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round 1\n",
    "my_match = my_match.append( make_match(md, \"Wild at Heart\", \"Pulp Fiction\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Out of Sight\", \"Saving Private Ryan\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Sixth Sense\", \"Toy Story\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Iron Giant\", \"Schindler's List\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Safe\", \"Fight Club\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Leon: The Professional\", \"Barton Fink\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"My Own Private Idaho\", \"Chungking Express\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Princess Mononoke\", \"Jackie Brown\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Close-Up\", \"The Silence of the Lambs\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Lion King\", \"Terminator 2: Judgment Day\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"JFK\", \"Heat\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Player\", \"Dazed and Confused\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Naked\", \"Boogie Nights\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Blue\", \"Malcolm X\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Truman Show\", \"The Big Lebowski\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Edward Scissorhands\", \"Groundhog Day\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"There's Something About Mary\", \"GoodFellas\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Miller's Crossing\", \"Jurassic Park\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"All About My Mother\", \"Magnolia\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Office Space\", \"Being John Malkovich\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Metropolitan\", \"Unforgiven\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Clueless\", \"Trainspotting\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Blair Witch Project\", \"The Matrix\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Thin Red Line\", \"Hoop Dreams\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Dead Man\", \"Fargo\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Glengarry Glen Ross\", \"L.A. Confidential\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Insider\", \"Before Sunrise\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Piano\", \"Eyes Wide Shut\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Sweet Hereafter\", \"Rushmore\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Usual Suspects\", \"The Shawshank Redemption\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Boyz n the Hood\", \"Reservoir Dogs\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Starship Troopers\", \"Se7en\", 0) )\n",
    "\n",
    "#Round 2\n",
    "my_match = my_match.append( make_match(md, \"Saving Private Ryan\", \"Pulp Fiction\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Schindler's List\", \"Toy Story\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Barton Fink\", \"Fight Club\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Chungking Express\", \"Jackie Brown\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Terminator 2: Judgment Day\", \"The Silence of the Lambs\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Heat\", \"Dazed and Confused\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Malcolm X\", \"Boogie Nights\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Groundhog Day\", \"The Big Lebowski\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Jurassic Park\", \"GoodFellas\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Being John Malkovich\", \"Magnolia\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Trainspotting\", \"Unforgiven\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Hoop Dreams\", \"The Matrix\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"L.A. Confidential\", \"Fargo\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Eyes Wide Shut\", \"Before Sunrise\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Shawshank Redemption\", \"Rushmore\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Se7en\", \"Reservoir Dogs\", 0) )\n",
    "\n",
    "#Round 3\n",
    "my_match = my_match.append( make_match(md, \"Toy Story\", \"Pulp Fiction\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Jackie Brown\", \"Fight Club\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Dazed and Confused\", \"The Silence of the Lambs\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Boogie Nights\", \"The Big Lebowski\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Being John Malkovich\", \"GoodFellas\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Unforgiven\", \"The Matrix\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Before Sunri se\", \"Fargo\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Se7en\", \"Rushmore\", 0) )\n",
    "\n",
    "#Round 4\n",
    "my_match = my_match.append( make_match(md, \"Fight Club\", \"Pulp Fiction\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Big Lebowski\", \"The Silence of the Lambs\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"The Matrix\", \"GoodFellas\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"Rushmore\", \"Fargo\", 0) )\n",
    "\n",
    "#Round 5\n",
    "my_match = my_match.append( make_match(md, \"The Silence of the Lambs\", \"Pulp Fiction\", 0) )\n",
    "my_match = my_match.append( make_match(md, \"GoodFellas\", \"Fargo\", 0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final match we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_match = make_match(md, \"Pulp Fiction\", \"Fargo\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final feature selection and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the years, which we kept unormalized earlier to select on it\n",
    "\n",
    "#Normalize year in final match\n",
    "final_match[['year_1']] = (final_match[['year_1']] - my_match[['year_1']].min(axis=0)) / (my_match[['year_1']].max(axis=0) - my_match[['year_1']].min(axis=0))\n",
    "final_match[['year_2']] = (final_match[['year_2']] - my_match[['year_2']].min(axis=0)) / (my_match[['year_2']].max(axis=0) - my_match[['year_2']].min(axis=0))\n",
    "\n",
    "#Normalize year in training/test data\n",
    "my_match[['year_1','year_2']] = minmax_scale(my_match[['year_1','year_2']])\n",
    "final_match[['year_1','year_2']] = minmax_scale(final_match[['year_1','year_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>title_1</th>\n",
       "      <th>year_1</th>\n",
       "      <th>return_1</th>\n",
       "      <th>budget_1</th>\n",
       "      <th>runtime_1</th>\n",
       "      <th>cast_size_1</th>\n",
       "      <th>crew_size_1</th>\n",
       "      <th>popularity_1</th>\n",
       "      <th>vote_count_1</th>\n",
       "      <th>...</th>\n",
       "      <th>year_2</th>\n",
       "      <th>return_2</th>\n",
       "      <th>budget_2</th>\n",
       "      <th>runtime_2</th>\n",
       "      <th>cast_size_2</th>\n",
       "      <th>crew_size_2</th>\n",
       "      <th>popularity_2</th>\n",
       "      <th>vote_count_2</th>\n",
       "      <th>vote_average_2</th>\n",
       "      <th>title_1_wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>680</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.237838e-06</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.205560</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.616013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.043062e-07</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.099443</td>\n",
       "      <td>0.067157</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>857</td>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>6.359469e-07</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.135243</td>\n",
       "      <td>0.127186</td>\n",
       "      <td>0.262572</td>\n",
       "      <td>0.041492</td>\n",
       "      <td>0.365800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>2.113277e-07</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.098648</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>0.015223</td>\n",
       "      <td>0.024084</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.085139e-06</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.065235</td>\n",
       "      <td>0.043806</td>\n",
       "      <td>0.253427</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>0.384768</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.437529e-06</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.165878</td>\n",
       "      <td>0.208318</td>\n",
       "      <td>0.035460</td>\n",
       "      <td>0.229042</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.259039e-06</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>0.155927</td>\n",
       "      <td>0.101519</td>\n",
       "      <td>0.085191</td>\n",
       "      <td>0.077896</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.073577e-07</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.069212</td>\n",
       "      <td>0.101919</td>\n",
       "      <td>0.107651</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>0.104504</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.098074e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.111376</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.041690</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.016737</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290</td>\n",
       "      <td>Barton Fink</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.358276e-07</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>0.045821</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>3.089861e-07</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.088305</td>\n",
       "      <td>0.129018</td>\n",
       "      <td>0.045001</td>\n",
       "      <td>0.039157</td>\n",
       "      <td>0.305058</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11104</td>\n",
       "      <td>Chungking Express</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081941</td>\n",
       "      <td>0.038825</td>\n",
       "      <td>0.032337</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.083532</td>\n",
       "      <td>0.039492</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>Jackie Brown</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.473672e-07</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.107632</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.112319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>5.658233e-07</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.107399</td>\n",
       "      <td>0.047603</td>\n",
       "      <td>0.160586</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.145070</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.238659e-06</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.191995</td>\n",
       "      <td>0.193345</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078759</td>\n",
       "      <td>0.047553</td>\n",
       "      <td>0.015027</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>5.001458e-07</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.109785</td>\n",
       "      <td>0.136663</td>\n",
       "      <td>0.127542</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.303708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.493700e-06</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.071599</td>\n",
       "      <td>0.099837</td>\n",
       "      <td>0.084920</td>\n",
       "      <td>0.041215</td>\n",
       "      <td>0.392228</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>949</td>\n",
       "      <td>Heat</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>3.326734e-07</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>0.213698</td>\n",
       "      <td>0.169133</td>\n",
       "      <td>0.034504</td>\n",
       "      <td>0.134058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4.949135e-07</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.151154</td>\n",
       "      <td>0.267697</td>\n",
       "      <td>0.163548</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>0.036516</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9571</td>\n",
       "      <td>Dazed and Confused</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.741162e-07</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.081941</td>\n",
       "      <td>0.056548</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2.995440e-07</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.099443</td>\n",
       "      <td>0.230387</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4995</td>\n",
       "      <td>Boogie Nights</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.124653e-07</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.124105</td>\n",
       "      <td>0.302892</td>\n",
       "      <td>0.044675</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.057758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>0.032946</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1883</td>\n",
       "      <td>Malcolm X</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.949570e-07</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.161496</td>\n",
       "      <td>0.216313</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063644</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>0.032718</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>The Big Lebowski</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.290721e-07</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.093874</td>\n",
       "      <td>0.140511</td>\n",
       "      <td>0.230098</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.213271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.357698e-07</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.082737</td>\n",
       "      <td>0.081765</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>0.025809</td>\n",
       "      <td>0.334115</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>Groundhog Day</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.724476e-07</td>\n",
       "      <td>0.038421</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.103330</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.167590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.944407e-07</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.084328</td>\n",
       "      <td>0.093274</td>\n",
       "      <td>0.035136</td>\n",
       "      <td>0.033934</td>\n",
       "      <td>0.265132</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769</td>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.317979e-07</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.116150</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>0.159812</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>0.228190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.377978e-06</td>\n",
       "      <td>0.060526</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.063810</td>\n",
       "      <td>0.211430</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>0.114876</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>329</td>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.258816e-06</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.101830</td>\n",
       "      <td>0.092924</td>\n",
       "      <td>0.279257</td>\n",
       "      <td>0.017984</td>\n",
       "      <td>0.352160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.099423e-07</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.092283</td>\n",
       "      <td>0.137013</td>\n",
       "      <td>0.102270</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.030691</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334</td>\n",
       "      <td>Magnolia</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.863050e-07</td>\n",
       "      <td>0.097368</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>0.097338</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>0.060031</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.425368e-07</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.086479</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.024013</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492</td>\n",
       "      <td>Being John Malkovich</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.225438e-07</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.057763</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.079923</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.841490e-07</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.071599</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.037174</td>\n",
       "      <td>0.024301</td>\n",
       "      <td>0.075945</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Unforgiven</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>9.977417e-07</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.080563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.078759</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>627</td>\n",
       "      <td>Trainspotting</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.132471e-07</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.100558</td>\n",
       "      <td>0.037099</td>\n",
       "      <td>0.194515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.077963</td>\n",
       "      <td>0.045671</td>\n",
       "      <td>0.025856</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.741820e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.115693</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>0.645070</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.335112e-04</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.065235</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>0.064960</td>\n",
       "      <td>0.028876</td>\n",
       "      <td>0.077508</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14275</td>\n",
       "      <td>Hoop Dreams</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>9.830760e-07</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.136834</td>\n",
       "      <td>0.009261</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>2.328945e-07</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>0.092708</td>\n",
       "      <td>0.045992</td>\n",
       "      <td>0.019661</td>\n",
       "      <td>0.056408</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275</td>\n",
       "      <td>Fargo</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.791670e-07</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.078759</td>\n",
       "      <td>0.057097</td>\n",
       "      <td>0.029348</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.147840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.097056</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.049810</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.028275</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2118</td>\n",
       "      <td>L.A. Confidential</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.715760e-07</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.110581</td>\n",
       "      <td>0.207935</td>\n",
       "      <td>0.222367</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.095269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.498839e-07</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.063010</td>\n",
       "      <td>0.094553</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.023515</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>Before Sunrise</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.592822e-07</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.084328</td>\n",
       "      <td>0.081432</td>\n",
       "      <td>0.027976</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>0.069977</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.347077e-07</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.125696</td>\n",
       "      <td>0.186598</td>\n",
       "      <td>0.102433</td>\n",
       "      <td>0.022529</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>345</td>\n",
       "      <td>Eyes Wide Shut</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.818331e-07</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.127287</td>\n",
       "      <td>0.059812</td>\n",
       "      <td>0.042378</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.090011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.425531e-06</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.097056</td>\n",
       "      <td>0.048453</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.015382</td>\n",
       "      <td>0.020673</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11545</td>\n",
       "      <td>Rushmore</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>2.339038e-07</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>0.048949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.333225e-07</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.029615</td>\n",
       "      <td>0.062039</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.721194e-07</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.113763</td>\n",
       "      <td>0.137546</td>\n",
       "      <td>0.210057</td>\n",
       "      <td>0.095983</td>\n",
       "      <td>0.593848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>3.944910e-07</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.085123</td>\n",
       "      <td>0.060462</td>\n",
       "      <td>0.151388</td>\n",
       "      <td>0.031546</td>\n",
       "      <td>0.236928</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>563</td>\n",
       "      <td>Starship Troopers</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.737944e-07</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.103421</td>\n",
       "      <td>0.068507</td>\n",
       "      <td>0.108928</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.112603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>8.807844e-07</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>0.101830</td>\n",
       "      <td>0.166345</td>\n",
       "      <td>0.214704</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>857</td>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>6.359469e-07</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.135243</td>\n",
       "      <td>0.127186</td>\n",
       "      <td>0.262572</td>\n",
       "      <td>0.041492</td>\n",
       "      <td>0.365800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.237838e-06</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.205560</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.616013</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>424</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.259039e-06</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>0.155927</td>\n",
       "      <td>0.101519</td>\n",
       "      <td>0.085191</td>\n",
       "      <td>0.077896</td>\n",
       "      <td>0.315217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.085139e-06</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.065235</td>\n",
       "      <td>0.043806</td>\n",
       "      <td>0.253427</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>0.384768</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290</td>\n",
       "      <td>Barton Fink</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.358276e-07</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>0.045821</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.032040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.098074e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.111376</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11104</td>\n",
       "      <td>Chungking Express</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081941</td>\n",
       "      <td>0.038825</td>\n",
       "      <td>0.032337</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.473672e-07</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.107632</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.112319</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>5.001458e-07</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.109785</td>\n",
       "      <td>0.136663</td>\n",
       "      <td>0.127542</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.303708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.238659e-06</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.191995</td>\n",
       "      <td>0.193345</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>949</td>\n",
       "      <td>Heat</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>3.326734e-07</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>0.213698</td>\n",
       "      <td>0.169133</td>\n",
       "      <td>0.034504</td>\n",
       "      <td>0.134058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.741162e-07</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.081941</td>\n",
       "      <td>0.056548</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1883</td>\n",
       "      <td>Malcolm X</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.949570e-07</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.161496</td>\n",
       "      <td>0.216313</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.124653e-07</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.124105</td>\n",
       "      <td>0.302892</td>\n",
       "      <td>0.044675</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.057758</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>Groundhog Day</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.724476e-07</td>\n",
       "      <td>0.038421</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.103330</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.167590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.290721e-07</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.093874</td>\n",
       "      <td>0.140511</td>\n",
       "      <td>0.230098</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.213271</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>329</td>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.258816e-06</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.101830</td>\n",
       "      <td>0.092924</td>\n",
       "      <td>0.279257</td>\n",
       "      <td>0.017984</td>\n",
       "      <td>0.352160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.317979e-07</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.116150</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>0.159812</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>0.228190</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492</td>\n",
       "      <td>Being John Malkovich</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.225438e-07</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.057763</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.079923</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.863050e-07</td>\n",
       "      <td>0.097368</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>0.097338</td>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>0.060031</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>627</td>\n",
       "      <td>Trainspotting</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.132471e-07</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.100558</td>\n",
       "      <td>0.037099</td>\n",
       "      <td>0.194515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>9.977417e-07</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.080563</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14275</td>\n",
       "      <td>Hoop Dreams</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>9.830760e-07</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.136834</td>\n",
       "      <td>0.009261</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.741820e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.115693</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>0.645070</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2118</td>\n",
       "      <td>L.A. Confidential</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.715760e-07</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.110581</td>\n",
       "      <td>0.207935</td>\n",
       "      <td>0.222367</td>\n",
       "      <td>0.021859</td>\n",
       "      <td>0.095269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.791670e-07</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.078759</td>\n",
       "      <td>0.057097</td>\n",
       "      <td>0.029348</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.147840</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>345</td>\n",
       "      <td>Eyes Wide Shut</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.818331e-07</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.127287</td>\n",
       "      <td>0.059812</td>\n",
       "      <td>0.042378</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.090011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.592822e-07</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.084328</td>\n",
       "      <td>0.081432</td>\n",
       "      <td>0.027976</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>0.069977</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.721194e-07</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.113763</td>\n",
       "      <td>0.137546</td>\n",
       "      <td>0.210057</td>\n",
       "      <td>0.095983</td>\n",
       "      <td>0.593848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>2.339038e-07</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>0.048949</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>807</td>\n",
       "      <td>Se7en</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>8.807844e-07</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>0.101830</td>\n",
       "      <td>0.166345</td>\n",
       "      <td>0.214704</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.066239e-06</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.079554</td>\n",
       "      <td>0.049169</td>\n",
       "      <td>0.150029</td>\n",
       "      <td>0.024103</td>\n",
       "      <td>0.271526</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.085139e-06</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.065235</td>\n",
       "      <td>0.043806</td>\n",
       "      <td>0.253427</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>0.384768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.237838e-06</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.205560</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.616013</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>Jackie Brown</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.473672e-07</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.107632</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.112319</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.098074e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.111376</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9571</td>\n",
       "      <td>Dazed and Confused</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.741162e-07</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.081941</td>\n",
       "      <td>0.056548</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>0.041844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.238659e-06</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.191995</td>\n",
       "      <td>0.193345</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4995</td>\n",
       "      <td>Boogie Nights</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.124653e-07</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.124105</td>\n",
       "      <td>0.302892</td>\n",
       "      <td>0.044675</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.057758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.290721e-07</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.093874</td>\n",
       "      <td>0.140511</td>\n",
       "      <td>0.230098</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.213271</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492</td>\n",
       "      <td>Being John Malkovich</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.225438e-07</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.057763</td>\n",
       "      <td>0.053955</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.079923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.317979e-07</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.116150</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>0.159812</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>0.228190</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Unforgiven</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>9.977417e-07</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.101944</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.080563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.741820e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.115693</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>0.645070</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>807</td>\n",
       "      <td>Se7en</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>8.807844e-07</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>0.101830</td>\n",
       "      <td>0.166345</td>\n",
       "      <td>0.214704</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>2.339038e-07</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>0.048949</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.098074e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.111376</td>\n",
       "      <td>0.259469</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>0.687624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.237838e-06</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.205560</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.616013</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>The Big Lebowski</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.290721e-07</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.093874</td>\n",
       "      <td>0.140511</td>\n",
       "      <td>0.230098</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.213271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.238659e-06</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.191995</td>\n",
       "      <td>0.193345</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603</td>\n",
       "      <td>The Matrix</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.741820e-07</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.115693</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.062656</td>\n",
       "      <td>0.645070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.317979e-07</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.116150</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>0.159812</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>0.228190</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11545</td>\n",
       "      <td>Rushmore</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>2.339038e-07</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>0.048949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.791670e-07</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.078759</td>\n",
       "      <td>0.057097</td>\n",
       "      <td>0.029348</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.147840</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.238659e-06</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.095465</td>\n",
       "      <td>0.191995</td>\n",
       "      <td>0.193345</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.237838e-06</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.123309</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.205560</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.616013</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769</td>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.317979e-07</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.116150</td>\n",
       "      <td>0.434608</td>\n",
       "      <td>0.159812</td>\n",
       "      <td>0.029944</td>\n",
       "      <td>0.228190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.791670e-07</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.078759</td>\n",
       "      <td>0.057097</td>\n",
       "      <td>0.029348</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.147840</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_1                     title_1    year_1      return_1  budget_1  \\\n",
       "0     680                Pulp Fiction  0.444444  2.237838e-06  0.021053   \n",
       "0     857         Saving Private Ryan  0.888889  6.359469e-07  0.184211   \n",
       "0     862                   Toy Story  0.555556  1.085139e-06  0.078947   \n",
       "0     424            Schindler's List  0.333333  1.259039e-06  0.057895   \n",
       "0     550                  Fight Club  1.000000  2.098074e-07  0.165789   \n",
       "0     290                 Barton Fink  0.111111  1.358276e-07  0.023684   \n",
       "0   11104           Chungking Express  0.444444  0.000000e+00  0.000000   \n",
       "0     184                Jackie Brown  0.777778  3.473672e-07  0.031579   \n",
       "0     274    The Silence of the Lambs  0.111111  1.238659e-06  0.050000   \n",
       "0     280  Terminator 2: Judgment Day  0.111111  5.001458e-07  0.263158   \n",
       "0     949                        Heat  0.555556  3.326734e-07  0.157895   \n",
       "0    9571          Dazed and Confused  0.333333  1.741162e-07  0.018158   \n",
       "0    4995               Boogie Nights  0.777778  3.124653e-07  0.039474   \n",
       "0    1883                   Malcolm X  0.222222  1.949570e-07  0.089474   \n",
       "0     115            The Big Lebowski  0.888889  3.290721e-07  0.039474   \n",
       "0     137               Groundhog Day  0.333333  4.724476e-07  0.038421   \n",
       "0     769                  GoodFellas  0.000000  2.317979e-07  0.065789   \n",
       "0     329               Jurassic Park  0.333333  1.258816e-06  0.165789   \n",
       "0     334                    Magnolia  1.000000  1.863050e-07  0.097368   \n",
       "0     492        Being John Malkovich  1.000000  2.225438e-07  0.034211   \n",
       "0      33                  Unforgiven  0.222222  9.977417e-07  0.036842   \n",
       "0     627               Trainspotting  0.666667  4.132471e-07  0.010526   \n",
       "0     603                  The Matrix  1.000000  6.741820e-07  0.165789   \n",
       "0   14275                 Hoop Dreams  0.444444  9.830760e-07  0.001842   \n",
       "0     275                       Fargo  0.666667  7.791670e-07  0.018421   \n",
       "0    2118           L.A. Confidential  0.777778  3.715760e-07  0.092105   \n",
       "0      76              Before Sunrise  0.555556  2.592822e-07  0.006579   \n",
       "0     345              Eyes Wide Shut  1.000000  2.818331e-07  0.171053   \n",
       "0   11545                    Rushmore  0.888889  2.339038e-07  0.023684   \n",
       "0     278    The Shawshank Redemption  0.444444  1.721194e-07  0.065789   \n",
       "..    ...                         ...       ...           ...       ...   \n",
       "0     563           Starship Troopers  0.777778  1.737944e-07  0.276316   \n",
       "0     857         Saving Private Ryan  0.888889  6.359469e-07  0.184211   \n",
       "0     424            Schindler's List  0.333333  1.259039e-06  0.057895   \n",
       "0     290                 Barton Fink  0.111111  1.358276e-07  0.023684   \n",
       "0   11104           Chungking Express  0.444444  0.000000e+00  0.000000   \n",
       "0     280  Terminator 2: Judgment Day  0.111111  5.001458e-07  0.263158   \n",
       "0     949                        Heat  0.555556  3.326734e-07  0.157895   \n",
       "0    1883                   Malcolm X  0.222222  1.949570e-07  0.089474   \n",
       "0     137               Groundhog Day  0.333333  4.724476e-07  0.038421   \n",
       "0     329               Jurassic Park  0.333333  1.258816e-06  0.165789   \n",
       "0     492        Being John Malkovich  1.000000  2.225438e-07  0.034211   \n",
       "0     627               Trainspotting  0.666667  4.132471e-07  0.010526   \n",
       "0   14275                 Hoop Dreams  0.444444  9.830760e-07  0.001842   \n",
       "0    2118           L.A. Confidential  0.777778  3.715760e-07  0.092105   \n",
       "0     345              Eyes Wide Shut  1.000000  2.818331e-07  0.171053   \n",
       "0     278    The Shawshank Redemption  0.444444  1.721194e-07  0.065789   \n",
       "0     807                       Se7en  0.555556  8.807844e-07  0.086842   \n",
       "0     862                   Toy Story  0.555556  1.085139e-06  0.078947   \n",
       "0     184                Jackie Brown  0.777778  3.473672e-07  0.031579   \n",
       "0    9571          Dazed and Confused  0.333333  1.741162e-07  0.018158   \n",
       "0    4995               Boogie Nights  0.777778  3.124653e-07  0.039474   \n",
       "0     492        Being John Malkovich  1.000000  2.225438e-07  0.034211   \n",
       "0      33                  Unforgiven  0.222222  9.977417e-07  0.036842   \n",
       "0     807                       Se7en  0.555556  8.807844e-07  0.086842   \n",
       "0     550                  Fight Club  1.000000  2.098074e-07  0.165789   \n",
       "0     115            The Big Lebowski  0.888889  3.290721e-07  0.039474   \n",
       "0     603                  The Matrix  1.000000  6.741820e-07  0.165789   \n",
       "0   11545                    Rushmore  0.888889  2.339038e-07  0.023684   \n",
       "0     274    The Silence of the Lambs  0.111111  1.238659e-06  0.050000   \n",
       "0     769                  GoodFellas  0.000000  2.317979e-07  0.065789   \n",
       "\n",
       "    runtime_1  cast_size_1  crew_size_1  popularity_1  vote_count_1  \\\n",
       "0    0.123309     0.180053     0.205560      0.258803      0.616013   \n",
       "0    0.135243     0.127186     0.262572      0.041492      0.365800   \n",
       "0    0.065235     0.043806     0.253427      0.041837      0.384768   \n",
       "0    0.155927     0.101519     0.085191      0.077896      0.315217   \n",
       "0    0.111376     0.259469     0.250275      0.118270      0.687624   \n",
       "0    0.093079     0.045821     0.038873      0.017114      0.032040   \n",
       "0    0.081941     0.038825     0.032337      0.014183      0.017761   \n",
       "0    0.123309     0.107632     0.022269      0.031752      0.112319   \n",
       "0    0.095465     0.191995     0.193345      0.009676      0.323245   \n",
       "0    0.109785     0.136663     0.127542      0.043140      0.303708   \n",
       "0    0.136038     0.213698     0.169133      0.034504      0.134058   \n",
       "0    0.081941     0.056548     0.018900      0.014340      0.041844   \n",
       "0    0.124105     0.302892     0.044675      0.015672      0.057758   \n",
       "0    0.161496     0.216313     0.040571      0.027725      0.026854   \n",
       "0    0.093874     0.140511     0.230098      0.030908      0.213271   \n",
       "0    0.081146     0.096322     0.103330      0.025506      0.167590   \n",
       "0    0.116150     0.434608     0.159812      0.029944      0.228190   \n",
       "0    0.101830     0.092924     0.279257      0.017984      0.352160   \n",
       "0    0.150358     0.097338     0.104553      0.018399      0.060031   \n",
       "0    0.089897     0.057763     0.053955      0.022637      0.079923   \n",
       "0    0.105012     0.109797     0.101944      0.021773      0.080563   \n",
       "0    0.074781     0.073620     0.100558      0.037099      0.194515   \n",
       "0    0.108990     0.115693     0.167203      0.062656      0.645070   \n",
       "0    0.136834     0.009261     0.007283      0.019101      0.006536   \n",
       "0    0.078759     0.057097     0.029348      0.024822      0.147840   \n",
       "0    0.110581     0.207935     0.222367      0.021859      0.095269   \n",
       "0    0.084328     0.081432     0.027976      0.022434      0.069977   \n",
       "0    0.127287     0.059812     0.042378      0.026014      0.090011   \n",
       "0    0.074781     0.043323     0.022079      0.012757      0.048949   \n",
       "0    0.113763     0.137546     0.210057      0.095983      0.593848   \n",
       "..        ...          ...          ...           ...           ...   \n",
       "0    0.103421     0.068507     0.108928      0.028100      0.112603   \n",
       "0    0.135243     0.127186     0.262572      0.041492      0.365800   \n",
       "0    0.155927     0.101519     0.085191      0.077896      0.315217   \n",
       "0    0.093079     0.045821     0.038873      0.017114      0.032040   \n",
       "0    0.081941     0.038825     0.032337      0.014183      0.017761   \n",
       "0    0.109785     0.136663     0.127542      0.043140      0.303708   \n",
       "0    0.136038     0.213698     0.169133      0.034504      0.134058   \n",
       "0    0.161496     0.216313     0.040571      0.027725      0.026854   \n",
       "0    0.081146     0.096322     0.103330      0.025506      0.167590   \n",
       "0    0.101830     0.092924     0.279257      0.017984      0.352160   \n",
       "0    0.089897     0.057763     0.053955      0.022637      0.079923   \n",
       "0    0.074781     0.073620     0.100558      0.037099      0.194515   \n",
       "0    0.136834     0.009261     0.007283      0.019101      0.006536   \n",
       "0    0.110581     0.207935     0.222367      0.021859      0.095269   \n",
       "0    0.127287     0.059812     0.042378      0.026014      0.090011   \n",
       "0    0.113763     0.137546     0.210057      0.095983      0.593848   \n",
       "0    0.101830     0.166345     0.214704      0.035475      0.420290   \n",
       "0    0.065235     0.043806     0.253427      0.041837      0.384768   \n",
       "0    0.123309     0.107632     0.022269      0.031752      0.112319   \n",
       "0    0.081941     0.056548     0.018900      0.014340      0.041844   \n",
       "0    0.124105     0.302892     0.044675      0.015672      0.057758   \n",
       "0    0.089897     0.057763     0.053955      0.022637      0.079923   \n",
       "0    0.105012     0.109797     0.101944      0.021773      0.080563   \n",
       "0    0.101830     0.166345     0.214704      0.035475      0.420290   \n",
       "0    0.111376     0.259469     0.250275      0.118270      0.687624   \n",
       "0    0.093874     0.140511     0.230098      0.030908      0.213271   \n",
       "0    0.108990     0.115693     0.167203      0.062656      0.645070   \n",
       "0    0.074781     0.043323     0.022079      0.012757      0.048949   \n",
       "0    0.095465     0.191995     0.193345      0.009676      0.323245   \n",
       "0    0.116150     0.434608     0.159812      0.029944      0.228190   \n",
       "\n",
       "        ...         year_2      return_2  budget_2  runtime_2  cast_size_2  \\\n",
       "0       ...       0.000000  2.043062e-07  0.025000   0.099443     0.067157   \n",
       "0       ...       0.888889  2.113277e-07  0.126316   0.098648     0.053266   \n",
       "0       ...       1.000000  1.437529e-06  0.105263   0.085919     0.165878   \n",
       "0       ...       1.000000  1.073577e-07  0.184211   0.069212     0.101919   \n",
       "0       ...       0.555556  0.000000e+00  0.000000   0.095465     0.041690   \n",
       "0       ...       0.444444  3.089861e-07  0.042105   0.088305     0.129018   \n",
       "0       ...       0.111111  0.000000e+00  0.006579   0.083532     0.039492   \n",
       "0       ...       0.777778  5.658233e-07  0.069737   0.107399     0.047603   \n",
       "0       ...       0.000000  0.000000e+00  0.000000   0.078759     0.047553   \n",
       "0       ...       0.444444  1.493700e-06  0.118421   0.071599     0.099837   \n",
       "0       ...       0.111111  4.949135e-07  0.105263   0.151154     0.267697   \n",
       "0       ...       0.222222  2.995440e-07  0.021053   0.099443     0.230387   \n",
       "0       ...       0.333333  0.000000e+00  0.000000   0.105012     0.032946   \n",
       "0       ...       0.333333  0.000000e+00  0.000000   0.063644     0.011992   \n",
       "0       ...       0.888889  4.357698e-07  0.157895   0.082737     0.081765   \n",
       "0       ...       0.000000  2.944407e-07  0.052632   0.084328     0.093274   \n",
       "0       ...       0.888889  1.377978e-06  0.060526   0.095465     0.063810   \n",
       "0       ...       0.000000  1.099423e-07  0.036842   0.092283     0.137013   \n",
       "0       ...       1.000000  7.425368e-07  0.021769   0.081146     0.086479   \n",
       "0       ...       1.000000  1.841490e-07  0.026316   0.071599     0.105000   \n",
       "0       ...       0.000000  0.000000e+00  0.000592   0.078759     0.018238   \n",
       "0       ...       0.555556  0.000000e+00  0.031579   0.077963     0.045671   \n",
       "0       ...       1.000000  3.335112e-04  0.000158   0.065235     0.030481   \n",
       "0       ...       0.888889  2.328945e-07  0.136842   0.136038     0.092708   \n",
       "0       ...       0.555556  0.000000e+00  0.023684   0.097056     0.061611   \n",
       "0       ...       0.222222  1.498839e-07  0.032895   0.080350     0.063010   \n",
       "0       ...       1.000000  1.347077e-07  0.236842   0.125696     0.186598   \n",
       "0       ...       0.333333  1.425531e-06  0.018421   0.097056     0.048453   \n",
       "0       ...       0.777778  1.333225e-07  0.013158   0.089897     0.029615   \n",
       "0       ...       0.555556  3.944910e-07  0.015789   0.085123     0.060462   \n",
       "..      ...            ...           ...       ...        ...          ...   \n",
       "0       ...       0.555556  8.807844e-07  0.086842   0.101830     0.166345   \n",
       "0       ...       0.444444  2.237838e-06  0.021053   0.123309     0.180053   \n",
       "0       ...       0.555556  1.085139e-06  0.078947   0.065235     0.043806   \n",
       "0       ...       1.000000  2.098074e-07  0.165789   0.111376     0.259469   \n",
       "0       ...       0.777778  3.473672e-07  0.031579   0.123309     0.107632   \n",
       "0       ...       0.111111  1.238659e-06  0.050000   0.095465     0.191995   \n",
       "0       ...       0.333333  1.741162e-07  0.018158   0.081941     0.056548   \n",
       "0       ...       0.777778  3.124653e-07  0.039474   0.124105     0.302892   \n",
       "0       ...       0.888889  3.290721e-07  0.039474   0.093874     0.140511   \n",
       "0       ...       0.000000  2.317979e-07  0.065789   0.116150     0.434608   \n",
       "0       ...       1.000000  1.863050e-07  0.097368   0.150358     0.097338   \n",
       "0       ...       0.222222  9.977417e-07  0.036842   0.105012     0.109797   \n",
       "0       ...       1.000000  6.741820e-07  0.165789   0.108990     0.115693   \n",
       "0       ...       0.666667  7.791670e-07  0.018421   0.078759     0.057097   \n",
       "0       ...       0.555556  2.592822e-07  0.006579   0.084328     0.081432   \n",
       "0       ...       0.888889  2.339038e-07  0.023684   0.074781     0.043323   \n",
       "0       ...       0.222222  1.066239e-06  0.003158   0.079554     0.049169   \n",
       "0       ...       0.444444  2.237838e-06  0.021053   0.123309     0.180053   \n",
       "0       ...       1.000000  2.098074e-07  0.165789   0.111376     0.259469   \n",
       "0       ...       0.111111  1.238659e-06  0.050000   0.095465     0.191995   \n",
       "0       ...       0.888889  3.290721e-07  0.039474   0.093874     0.140511   \n",
       "0       ...       0.000000  2.317979e-07  0.065789   0.116150     0.434608   \n",
       "0       ...       1.000000  6.741820e-07  0.165789   0.108990     0.115693   \n",
       "0       ...       0.888889  2.339038e-07  0.023684   0.074781     0.043323   \n",
       "0       ...       0.444444  2.237838e-06  0.021053   0.123309     0.180053   \n",
       "0       ...       0.111111  1.238659e-06  0.050000   0.095465     0.191995   \n",
       "0       ...       0.000000  2.317979e-07  0.065789   0.116150     0.434608   \n",
       "0       ...       0.666667  7.791670e-07  0.018421   0.078759     0.057097   \n",
       "0       ...       0.444444  2.237838e-06  0.021053   0.123309     0.180053   \n",
       "0       ...       0.666667  7.791670e-07  0.018421   0.078759     0.057097   \n",
       "\n",
       "    crew_size_2  popularity_2  vote_count_2  vote_average_2  title_1_wins  \n",
       "0      0.034810      0.017373      0.024297        0.727273             1  \n",
       "0      0.030177      0.015223      0.024084        0.681818             1  \n",
       "0      0.208318      0.035460      0.229042        0.790909             1  \n",
       "0      0.107651      0.029976      0.104504        0.781818             1  \n",
       "0      0.021250      0.016737      0.004476        0.745455             1  \n",
       "0      0.045001      0.039157      0.305058        0.836364             1  \n",
       "0      0.025938      0.015114      0.015558        0.736364             1  \n",
       "0      0.160586      0.033121      0.145070        0.836364             1  \n",
       "0      0.015027      0.007242      0.003836        0.818182             1  \n",
       "0      0.084920      0.041215      0.392228        0.818182             1  \n",
       "0      0.163548      0.027007      0.036516        0.772727             1  \n",
       "0      0.027229      0.013183      0.012077        0.718182             1  \n",
       "0      0.014199      0.017622      0.007531        0.772727             1  \n",
       "0      0.032718      0.004444      0.001279        0.772727             1  \n",
       "0      0.068615      0.025809      0.334115        0.800000             1  \n",
       "0      0.035136      0.033934      0.265132        0.772727             1  \n",
       "0      0.211430      0.023134      0.114876        0.681818             1  \n",
       "0      0.102270      0.015490      0.030691        0.772727             1  \n",
       "0      0.075667      0.020057      0.024013        0.763636             1  \n",
       "0      0.037174      0.024301      0.075945        0.763636             1  \n",
       "0      0.005136      0.004893      0.002842        0.727273             1  \n",
       "0      0.025856      0.019841      0.058895        0.718182             1  \n",
       "0      0.064960      0.028876      0.077508        0.663636             1  \n",
       "0      0.045992      0.019661      0.056408        0.745455             1  \n",
       "0      0.049810      0.013684      0.028275        0.745455             1  \n",
       "0      0.094553      0.014207      0.023515        0.772727             1  \n",
       "0      0.102433      0.022529      0.034811        0.754545             1  \n",
       "0      0.016943      0.015382      0.020673        0.736364             1  \n",
       "0      0.062039      0.012768      0.007744        0.709091             1  \n",
       "0      0.151388      0.031546      0.236928        0.827273             1  \n",
       "..          ...           ...           ...             ...           ...  \n",
       "0      0.214704      0.035475      0.420290        0.827273             0  \n",
       "0      0.205560      0.258803      0.616013        0.845455             0  \n",
       "0      0.253427      0.041837      0.384768        0.790909             0  \n",
       "0      0.250275      0.118270      0.687624        0.845455             0  \n",
       "0      0.022269      0.031752      0.112319        0.754545             0  \n",
       "0      0.193345      0.009676      0.323245        0.827273             0  \n",
       "0      0.018900      0.014340      0.041844        0.763636             0  \n",
       "0      0.044675      0.015672      0.057758        0.772727             0  \n",
       "0      0.230098      0.030908      0.213271        0.800000             0  \n",
       "0      0.159812      0.029944      0.228190        0.836364             0  \n",
       "0      0.104553      0.018399      0.060031        0.772727             0  \n",
       "0      0.101944      0.021773      0.080563        0.790909             0  \n",
       "0      0.167203      0.062656      0.645070        0.809091             0  \n",
       "0      0.029348      0.024822      0.147840        0.790909             0  \n",
       "0      0.027976      0.022434      0.069977        0.790909             0  \n",
       "0      0.022079      0.012757      0.048949        0.772727             0  \n",
       "0      0.150029      0.024103      0.271526        0.827273             0  \n",
       "0      0.205560      0.258803      0.616013        0.845455             0  \n",
       "0      0.250275      0.118270      0.687624        0.845455             0  \n",
       "0      0.193345      0.009676      0.323245        0.827273             0  \n",
       "0      0.230098      0.030908      0.213271        0.800000             0  \n",
       "0      0.159812      0.029944      0.228190        0.836364             0  \n",
       "0      0.167203      0.062656      0.645070        0.809091             0  \n",
       "0      0.022079      0.012757      0.048949        0.772727             0  \n",
       "0      0.205560      0.258803      0.616013        0.845455             0  \n",
       "0      0.193345      0.009676      0.323245        0.827273             0  \n",
       "0      0.159812      0.029944      0.228190        0.836364             0  \n",
       "0      0.029348      0.024822      0.147840        0.790909             0  \n",
       "0      0.205560      0.258803      0.616013        0.845455             0  \n",
       "0      0.029348      0.024822      0.147840        0.790909             0  \n",
       "\n",
       "[123 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplest splitting -- random.  Could rethink this to e.g. keep final match movies equal in # of samples?\n",
    "my_match_train, my_match_test = train_test_split(my_match, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 23)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 23)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_match_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rushmore The Sweet Hereafter\n",
      "GoodFellas There's Something About Mary\n",
      "All About My Mother Magnolia\n",
      "Eyes Wide Shut The Piano\n",
      "Terminator 2: Judgment Day The Silence of the Lambs\n",
      "Eyes Wide Shut Before Sunrise\n",
      "Schindler's List The Iron Giant\n",
      "Boogie Nights Malcolm X\n",
      "JFK Heat\n",
      "Rushmore The Shawshank Redemption\n",
      "The Insider Before Sunrise\n",
      "Trainspotting Unforgiven\n",
      "The Silence of the Lambs The Big Lebowski\n",
      "Pulp Fiction Saving Private Ryan\n",
      "Unforgiven The Matrix\n",
      "Fargo Rushmore\n",
      "The Shawshank Redemption The Usual Suspects\n",
      "Se7en Reservoir Dogs\n",
      "Naked Boogie Nights\n",
      "Dead Man Fargo\n",
      "The Lion King Terminator 2: Judgment Day\n",
      "L.A. Confidential Fargo\n",
      "The Big Lebowski The Truman Show\n",
      "Boyz n the Hood Reservoir Dogs\n",
      "Jurassic Park GoodFellas\n"
     ]
    }
   ],
   "source": [
    "#These are the train samples we will remove because they are in test set with reverse order\n",
    "for index, row in my_match_train.iterrows(): \n",
    "    #print(row['title_1'], row['title_2'])\n",
    "    for index2, row2 in my_match_test.iterrows():\n",
    "        if(row['title_1']==row2['title_2'] and row['title_2']==row2['title_1']):\n",
    "            print(row['title_1'], row['title_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we remove from training set any of the reverse order duplicate matches that exist in the test set\n",
    "keys1 = ['title_1', 'title_2']\n",
    "keys2 = ['title_2', 'title_1']\n",
    "\n",
    "i_train = my_match_train.set_index(keys1).index\n",
    "i_test = my_match_test.set_index(keys2).index\n",
    "my_match_train = my_match_train[~i_train.isin(i_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check they're gone\n",
    "for index, row in my_match_train.iterrows(): \n",
    "    #print(row['title_1'], row['title_2'])\n",
    "    for index2, row2 in my_match_test.iterrows():\n",
    "        if(row['title_1']==row2['title_2'] and row['title_2']==row2['title_1']):\n",
    "            print(row['title_1'], row['title_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the features that will be trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = ['year_1','budget_1','return_1','cast_size_1','crew_size_1','popularity_1','vote_count_1',\"vote_average_1\",'year_2','budget_2','return_2','cast_size_2','crew_size_2','popularity_2','vote_count_2',\"vote_average_2\"]\n",
    "#columns = ['year_1','budget_1','return_1','cast_size_1','popularity_1','vote_count_1',\"vote_average_1\",'year_2','budget_2','return_2','cast_size_2','popularity_2','vote_count_2',\"vote_average_2\"]\n",
    "#columns = ['return_1','popularity_1','vote_count_1','vote_average_1', 'cast_size_1','return_2','popularity_2','vote_count_2','vote_average_2', 'cast_size_2']\n",
    "#columns = ['popularity_1','vote_count_1',\"vote_average_1\",'popularity_2','vote_count_2',\"vote_average_2\"]\n",
    "\n",
    "\n",
    "#The best of the ones I tried:\n",
    "columns = ['return_1','popularity_1','vote_count_1',\"vote_average_1\",'return_2','popularity_2','vote_count_2',\"vote_average_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = my_match_train[columns]\n",
    "X_test = my_match_test[columns]\n",
    "X_final = final_match[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = my_match_train[['title_1_wins']]\n",
    "y_test = my_match_test[['title_1_wins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return_1</th>\n",
       "      <th>popularity_1</th>\n",
       "      <th>vote_count_1</th>\n",
       "      <th>vote_average_1</th>\n",
       "      <th>return_2</th>\n",
       "      <th>popularity_2</th>\n",
       "      <th>vote_count_2</th>\n",
       "      <th>vote_average_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.616013</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>7.791670e-07</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.14784</td>\n",
       "      <td>0.790909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   return_1  popularity_1  vote_count_1  vote_average_1      return_2  \\\n",
       "0  0.000002      0.258803      0.616013        0.845455  7.791670e-07   \n",
       "\n",
       "   popularity_2  vote_count_2  vote_average_2  \n",
       "0      0.024822       0.14784        0.790909  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "Not optimal with so few features though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kreis/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import matplotlib\n",
    "#from callbacks import all_callbacks #this doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Not really ideal with so few samples...  Let's see how this goes\n",
    "model.add(Dense(12, input_shape = X_train.shape[1:2], activation = 'relu', kernel_initializer='lecun_uniform'))\n",
    "#model.add(Dense(12, activation = 'relu', kernel_initializer='lecun_uniform'))\n",
    "#model.add(Dense(6, activation = 'relu', kernel_initializer='lecun_uniform'))\n",
    "model.add(Dense(y_train.shape[1], activation = 'sigmoid', kernel_initializer='lecun_uniform'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a binary classification problem (https://keras.io/getting-started/sequential-model-guide/)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7054 - acc: 0.5088\n",
      "Epoch 2/300\n",
      "57/57 [==============================] - 0s 197us/step - loss: 0.7023 - acc: 0.5088\n",
      "Epoch 3/300\n",
      "57/57 [==============================] - 0s 213us/step - loss: 0.7013 - acc: 0.5088\n",
      "Epoch 4/300\n",
      "57/57 [==============================] - 0s 190us/step - loss: 0.7004 - acc: 0.5088\n",
      "Epoch 5/300\n",
      "57/57 [==============================] - 0s 214us/step - loss: 0.6994 - acc: 0.5088\n",
      "Epoch 6/300\n",
      "57/57 [==============================] - 0s 224us/step - loss: 0.6987 - acc: 0.5088\n",
      "Epoch 7/300\n",
      "57/57 [==============================] - 0s 279us/step - loss: 0.6970 - acc: 0.5088\n",
      "Epoch 8/300\n",
      "57/57 [==============================] - 0s 513us/step - loss: 0.6959 - acc: 0.5088\n",
      "Epoch 9/300\n",
      "57/57 [==============================] - 0s 215us/step - loss: 0.6954 - acc: 0.5088\n",
      "Epoch 10/300\n",
      "57/57 [==============================] - 0s 313us/step - loss: 0.6953 - acc: 0.5088\n",
      "Epoch 11/300\n",
      "57/57 [==============================] - 0s 209us/step - loss: 0.6933 - acc: 0.5088\n",
      "Epoch 12/300\n",
      "57/57 [==============================] - 0s 210us/step - loss: 0.6928 - acc: 0.5088\n",
      "Epoch 13/300\n",
      "57/57 [==============================] - 0s 464us/step - loss: 0.6919 - acc: 0.5088\n",
      "Epoch 14/300\n",
      "57/57 [==============================] - 0s 274us/step - loss: 0.6907 - acc: 0.5088\n",
      "Epoch 15/300\n",
      "57/57 [==============================] - 0s 252us/step - loss: 0.6897 - acc: 0.5088\n",
      "Epoch 16/300\n",
      "57/57 [==============================] - 0s 206us/step - loss: 0.6892 - acc: 0.5263\n",
      "Epoch 17/300\n",
      "57/57 [==============================] - 0s 204us/step - loss: 0.6881 - acc: 0.5088\n",
      "Epoch 18/300\n",
      "57/57 [==============================] - 0s 204us/step - loss: 0.6871 - acc: 0.5439\n",
      "Epoch 19/300\n",
      "57/57 [==============================] - 0s 328us/step - loss: 0.6857 - acc: 0.5263\n",
      "Epoch 20/300\n",
      "57/57 [==============================] - 0s 290us/step - loss: 0.6857 - acc: 0.5789\n",
      "Epoch 21/300\n",
      "57/57 [==============================] - 0s 293us/step - loss: 0.6843 - acc: 0.5965\n",
      "Epoch 22/300\n",
      "57/57 [==============================] - 0s 207us/step - loss: 0.6841 - acc: 0.5614\n",
      "Epoch 23/300\n",
      "57/57 [==============================] - 0s 194us/step - loss: 0.6828 - acc: 0.5789\n",
      "Epoch 24/300\n",
      "57/57 [==============================] - 0s 172us/step - loss: 0.6820 - acc: 0.5965\n",
      "Epoch 25/300\n",
      "57/57 [==============================] - 0s 219us/step - loss: 0.6811 - acc: 0.5789\n",
      "Epoch 26/300\n",
      "57/57 [==============================] - 0s 213us/step - loss: 0.6801 - acc: 0.5789\n",
      "Epoch 27/300\n",
      "57/57 [==============================] - 0s 228us/step - loss: 0.6798 - acc: 0.6491\n",
      "Epoch 28/300\n",
      "57/57 [==============================] - 0s 362us/step - loss: 0.6786 - acc: 0.6140\n",
      "Epoch 29/300\n",
      "57/57 [==============================] - 0s 340us/step - loss: 0.6784 - acc: 0.6491\n",
      "Epoch 30/300\n",
      "57/57 [==============================] - 0s 246us/step - loss: 0.6777 - acc: 0.6491\n",
      "Epoch 31/300\n",
      "57/57 [==============================] - 0s 192us/step - loss: 0.6767 - acc: 0.6491\n",
      "Epoch 32/300\n",
      "57/57 [==============================] - 0s 188us/step - loss: 0.6760 - acc: 0.6491\n",
      "Epoch 33/300\n",
      "57/57 [==============================] - 0s 204us/step - loss: 0.6755 - acc: 0.6667\n",
      "Epoch 34/300\n",
      "57/57 [==============================] - 0s 216us/step - loss: 0.6746 - acc: 0.6316\n",
      "Epoch 35/300\n",
      "57/57 [==============================] - 0s 242us/step - loss: 0.6737 - acc: 0.6667\n",
      "Epoch 36/300\n",
      "57/57 [==============================] - 0s 300us/step - loss: 0.6731 - acc: 0.6491\n",
      "Epoch 37/300\n",
      "57/57 [==============================] - 0s 479us/step - loss: 0.6721 - acc: 0.6491\n",
      "Epoch 38/300\n",
      "57/57 [==============================] - 0s 274us/step - loss: 0.6724 - acc: 0.6140\n",
      "Epoch 39/300\n",
      "57/57 [==============================] - 0s 211us/step - loss: 0.6709 - acc: 0.6667\n",
      "Epoch 40/300\n",
      "57/57 [==============================] - 0s 234us/step - loss: 0.6697 - acc: 0.6667\n",
      "Epoch 41/300\n",
      "57/57 [==============================] - 0s 186us/step - loss: 0.6692 - acc: 0.6667\n",
      "Epoch 42/300\n",
      "57/57 [==============================] - 0s 221us/step - loss: 0.6688 - acc: 0.6667\n",
      "Epoch 43/300\n",
      "57/57 [==============================] - 0s 237us/step - loss: 0.6678 - acc: 0.7018\n",
      "Epoch 44/300\n",
      "57/57 [==============================] - 0s 210us/step - loss: 0.6671 - acc: 0.6316\n",
      "Epoch 45/300\n",
      "57/57 [==============================] - 0s 459us/step - loss: 0.6660 - acc: 0.7018\n",
      "Epoch 46/300\n",
      "57/57 [==============================] - 0s 301us/step - loss: 0.6655 - acc: 0.7018\n",
      "Epoch 47/300\n",
      "57/57 [==============================] - 0s 183us/step - loss: 0.6645 - acc: 0.6842\n",
      "Epoch 48/300\n",
      "57/57 [==============================] - 0s 214us/step - loss: 0.6647 - acc: 0.6667\n",
      "Epoch 49/300\n",
      "57/57 [==============================] - 0s 182us/step - loss: 0.6637 - acc: 0.7018\n",
      "Epoch 50/300\n",
      "57/57 [==============================] - 0s 205us/step - loss: 0.6631 - acc: 0.7193\n",
      "Epoch 51/300\n",
      "57/57 [==============================] - 0s 241us/step - loss: 0.6617 - acc: 0.6842\n",
      "Epoch 52/300\n",
      "57/57 [==============================] - 0s 253us/step - loss: 0.6611 - acc: 0.7193\n",
      "Epoch 53/300\n",
      "57/57 [==============================] - 0s 236us/step - loss: 0.6605 - acc: 0.7368\n",
      "Epoch 54/300\n",
      "57/57 [==============================] - 0s 426us/step - loss: 0.6601 - acc: 0.7018\n",
      "Epoch 55/300\n",
      "57/57 [==============================] - 0s 260us/step - loss: 0.6595 - acc: 0.7018\n",
      "Epoch 56/300\n",
      "57/57 [==============================] - 0s 323us/step - loss: 0.6587 - acc: 0.7368\n",
      "Epoch 57/300\n",
      "57/57 [==============================] - 0s 222us/step - loss: 0.6580 - acc: 0.7368\n",
      "Epoch 58/300\n",
      "57/57 [==============================] - 0s 197us/step - loss: 0.6582 - acc: 0.7193\n",
      "Epoch 59/300\n",
      "57/57 [==============================] - 0s 190us/step - loss: 0.6568 - acc: 0.7368\n",
      "Epoch 60/300\n",
      "57/57 [==============================] - 0s 217us/step - loss: 0.6559 - acc: 0.7193\n",
      "Epoch 61/300\n",
      "57/57 [==============================] - 0s 184us/step - loss: 0.6553 - acc: 0.7193\n",
      "Epoch 62/300\n",
      "57/57 [==============================] - 0s 186us/step - loss: 0.6544 - acc: 0.7193\n",
      "Epoch 63/300\n",
      "57/57 [==============================] - 0s 174us/step - loss: 0.6541 - acc: 0.7193\n",
      "Epoch 64/300\n",
      "57/57 [==============================] - 0s 189us/step - loss: 0.6534 - acc: 0.7368\n",
      "Epoch 65/300\n",
      "57/57 [==============================] - 0s 219us/step - loss: 0.6525 - acc: 0.6842\n",
      "Epoch 66/300\n",
      "57/57 [==============================] - 0s 392us/step - loss: 0.6515 - acc: 0.7018\n",
      "Epoch 67/300\n",
      "57/57 [==============================] - 0s 337us/step - loss: 0.6519 - acc: 0.7018\n",
      "Epoch 68/300\n",
      "57/57 [==============================] - 0s 322us/step - loss: 0.6504 - acc: 0.7193\n",
      "Epoch 69/300\n",
      "57/57 [==============================] - 0s 197us/step - loss: 0.6497 - acc: 0.7193\n",
      "Epoch 70/300\n",
      "57/57 [==============================] - 0s 195us/step - loss: 0.6491 - acc: 0.7018\n",
      "Epoch 71/300\n",
      "57/57 [==============================] - 0s 234us/step - loss: 0.6487 - acc: 0.7193\n",
      "Epoch 72/300\n",
      "57/57 [==============================] - 0s 203us/step - loss: 0.6489 - acc: 0.7018\n",
      "Epoch 73/300\n",
      "57/57 [==============================] - 0s 215us/step - loss: 0.6469 - acc: 0.7368\n",
      "Epoch 74/300\n",
      "57/57 [==============================] - 0s 219us/step - loss: 0.6467 - acc: 0.7368\n",
      "Epoch 75/300\n",
      "57/57 [==============================] - 0s 218us/step - loss: 0.6458 - acc: 0.7193\n",
      "Epoch 76/300\n",
      "57/57 [==============================] - 0s 198us/step - loss: 0.6453 - acc: 0.7193\n",
      "Epoch 77/300\n",
      "57/57 [==============================] - 0s 256us/step - loss: 0.6441 - acc: 0.7193\n",
      "Epoch 78/300\n",
      "57/57 [==============================] - 0s 445us/step - loss: 0.6435 - acc: 0.7193\n",
      "Epoch 79/300\n",
      "57/57 [==============================] - 0s 353us/step - loss: 0.6432 - acc: 0.7193\n",
      "Epoch 80/300\n",
      "57/57 [==============================] - 0s 301us/step - loss: 0.6428 - acc: 0.7368\n",
      "Epoch 81/300\n",
      "57/57 [==============================] - 0s 316us/step - loss: 0.6415 - acc: 0.7193\n",
      "Epoch 82/300\n",
      "57/57 [==============================] - 0s 207us/step - loss: 0.6413 - acc: 0.7193\n",
      "Epoch 83/300\n",
      "57/57 [==============================] - 0s 219us/step - loss: 0.6398 - acc: 0.7368\n",
      "Epoch 84/300\n",
      "57/57 [==============================] - 0s 336us/step - loss: 0.6394 - acc: 0.7193\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 281us/step - loss: 0.6388 - acc: 0.7368\n",
      "Epoch 86/300\n",
      "57/57 [==============================] - 0s 241us/step - loss: 0.6382 - acc: 0.7018\n",
      "Epoch 87/300\n",
      "57/57 [==============================] - 0s 231us/step - loss: 0.6374 - acc: 0.7018\n",
      "Epoch 88/300\n",
      "57/57 [==============================] - 0s 223us/step - loss: 0.6366 - acc: 0.7018\n",
      "Epoch 89/300\n",
      "57/57 [==============================] - 0s 253us/step - loss: 0.6358 - acc: 0.7193\n",
      "Epoch 90/300\n",
      "57/57 [==============================] - 0s 347us/step - loss: 0.6351 - acc: 0.7018\n",
      "Epoch 91/300\n",
      "57/57 [==============================] - 0s 310us/step - loss: 0.6345 - acc: 0.7018\n",
      "Epoch 92/300\n",
      "57/57 [==============================] - 0s 251us/step - loss: 0.6333 - acc: 0.7193\n",
      "Epoch 93/300\n",
      "57/57 [==============================] - 0s 201us/step - loss: 0.6330 - acc: 0.6842\n",
      "Epoch 94/300\n",
      "57/57 [==============================] - 0s 250us/step - loss: 0.6329 - acc: 0.7018\n",
      "Epoch 95/300\n",
      "57/57 [==============================] - 0s 236us/step - loss: 0.6315 - acc: 0.7193\n",
      "Epoch 96/300\n",
      "57/57 [==============================] - 0s 377us/step - loss: 0.6312 - acc: 0.7368\n",
      "Epoch 97/300\n",
      "57/57 [==============================] - 0s 376us/step - loss: 0.6304 - acc: 0.7193\n",
      "Epoch 98/300\n",
      "57/57 [==============================] - 0s 335us/step - loss: 0.6294 - acc: 0.7193\n",
      "Epoch 99/300\n",
      "57/57 [==============================] - 0s 388us/step - loss: 0.6298 - acc: 0.7018\n",
      "Epoch 100/300\n",
      "57/57 [==============================] - 0s 261us/step - loss: 0.6283 - acc: 0.7368\n",
      "Epoch 101/300\n",
      "57/57 [==============================] - 0s 305us/step - loss: 0.6274 - acc: 0.7193\n",
      "Epoch 102/300\n",
      "57/57 [==============================] - 0s 274us/step - loss: 0.6272 - acc: 0.7193\n",
      "Epoch 103/300\n",
      "57/57 [==============================] - 0s 383us/step - loss: 0.6262 - acc: 0.7368\n",
      "Epoch 104/300\n",
      "57/57 [==============================] - 0s 249us/step - loss: 0.6257 - acc: 0.7018\n",
      "Epoch 105/300\n",
      "57/57 [==============================] - 0s 278us/step - loss: 0.6248 - acc: 0.7193\n",
      "Epoch 106/300\n",
      "57/57 [==============================] - 0s 327us/step - loss: 0.6247 - acc: 0.7018\n",
      "Epoch 107/300\n",
      "57/57 [==============================] - 0s 215us/step - loss: 0.6235 - acc: 0.7193\n",
      "Epoch 108/300\n",
      "57/57 [==============================] - 0s 213us/step - loss: 0.6224 - acc: 0.7368\n",
      "Epoch 109/300\n",
      "57/57 [==============================] - 0s 354us/step - loss: 0.6221 - acc: 0.7018\n",
      "Epoch 110/300\n",
      "57/57 [==============================] - 0s 224us/step - loss: 0.6215 - acc: 0.7544\n",
      "Epoch 111/300\n",
      "57/57 [==============================] - 0s 219us/step - loss: 0.6216 - acc: 0.7193\n",
      "Epoch 112/300\n",
      "57/57 [==============================] - 0s 292us/step - loss: 0.6200 - acc: 0.7368\n",
      "Epoch 113/300\n",
      "57/57 [==============================] - 0s 340us/step - loss: 0.6202 - acc: 0.7018\n",
      "Epoch 114/300\n",
      "57/57 [==============================] - 0s 228us/step - loss: 0.6187 - acc: 0.7368\n",
      "Epoch 115/300\n",
      "57/57 [==============================] - 0s 276us/step - loss: 0.6185 - acc: 0.7018\n",
      "Epoch 116/300\n",
      "57/57 [==============================] - 0s 310us/step - loss: 0.6172 - acc: 0.7018\n",
      "Epoch 117/300\n",
      "57/57 [==============================] - 0s 273us/step - loss: 0.6167 - acc: 0.7018\n",
      "Epoch 118/300\n",
      "57/57 [==============================] - 0s 335us/step - loss: 0.6161 - acc: 0.7368\n",
      "Epoch 119/300\n",
      "57/57 [==============================] - 0s 220us/step - loss: 0.6160 - acc: 0.7368\n",
      "Epoch 120/300\n",
      "57/57 [==============================] - 0s 293us/step - loss: 0.6150 - acc: 0.7368\n",
      "Epoch 121/300\n",
      "57/57 [==============================] - 0s 269us/step - loss: 0.6143 - acc: 0.7018\n",
      "Epoch 122/300\n",
      "57/57 [==============================] - 0s 227us/step - loss: 0.6132 - acc: 0.7544\n",
      "Epoch 123/300\n",
      "57/57 [==============================] - 0s 204us/step - loss: 0.6134 - acc: 0.7018\n",
      "Epoch 124/300\n",
      "57/57 [==============================] - 0s 277us/step - loss: 0.6121 - acc: 0.7018\n",
      "Epoch 125/300\n",
      "57/57 [==============================] - 0s 202us/step - loss: 0.6115 - acc: 0.7018\n",
      "Epoch 126/300\n",
      "57/57 [==============================] - 0s 189us/step - loss: 0.6117 - acc: 0.7018\n",
      "Epoch 127/300\n",
      "57/57 [==============================] - 0s 280us/step - loss: 0.6112 - acc: 0.7193\n",
      "Epoch 128/300\n",
      "57/57 [==============================] - 0s 229us/step - loss: 0.6099 - acc: 0.7368\n",
      "Epoch 129/300\n",
      "57/57 [==============================] - 0s 274us/step - loss: 0.6093 - acc: 0.7193\n",
      "Epoch 130/300\n",
      "57/57 [==============================] - 0s 289us/step - loss: 0.6086 - acc: 0.7018\n",
      "Epoch 131/300\n",
      "57/57 [==============================] - 0s 352us/step - loss: 0.6086 - acc: 0.7368\n",
      "Epoch 132/300\n",
      "57/57 [==============================] - 0s 233us/step - loss: 0.6080 - acc: 0.7018\n",
      "Epoch 133/300\n",
      "57/57 [==============================] - 0s 293us/step - loss: 0.6069 - acc: 0.7368\n",
      "Epoch 134/300\n",
      "57/57 [==============================] - 0s 321us/step - loss: 0.6061 - acc: 0.7193\n",
      "Epoch 135/300\n",
      "57/57 [==============================] - 0s 245us/step - loss: 0.6063 - acc: 0.7018\n",
      "Epoch 136/300\n",
      "57/57 [==============================] - 0s 269us/step - loss: 0.6053 - acc: 0.7018\n",
      "Epoch 137/300\n",
      "57/57 [==============================] - 0s 351us/step - loss: 0.6047 - acc: 0.7193\n",
      "Epoch 138/300\n",
      "57/57 [==============================] - 0s 199us/step - loss: 0.6051 - acc: 0.7368\n",
      "Epoch 139/300\n",
      "57/57 [==============================] - 0s 244us/step - loss: 0.6036 - acc: 0.7544\n",
      "Epoch 140/300\n",
      "57/57 [==============================] - 0s 332us/step - loss: 0.6030 - acc: 0.7368\n",
      "Epoch 141/300\n",
      "57/57 [==============================] - 0s 251us/step - loss: 0.6032 - acc: 0.7018\n",
      "Epoch 142/300\n",
      "57/57 [==============================] - 0s 228us/step - loss: 0.6015 - acc: 0.7193\n",
      "Epoch 143/300\n",
      "57/57 [==============================] - 0s 309us/step - loss: 0.6038 - acc: 0.7193\n",
      "Epoch 144/300\n",
      "57/57 [==============================] - 0s 264us/step - loss: 0.6016 - acc: 0.7018\n",
      "Epoch 145/300\n",
      "57/57 [==============================] - 0s 239us/step - loss: 0.6002 - acc: 0.7193\n",
      "Epoch 146/300\n",
      "57/57 [==============================] - 0s 317us/step - loss: 0.6008 - acc: 0.7193\n",
      "Epoch 147/300\n",
      "57/57 [==============================] - 0s 266us/step - loss: 0.5993 - acc: 0.7193\n",
      "Epoch 148/300\n",
      "57/57 [==============================] - 0s 229us/step - loss: 0.5991 - acc: 0.7193\n",
      "Epoch 149/300\n",
      "57/57 [==============================] - 0s 239us/step - loss: 0.5987 - acc: 0.7193\n",
      "Epoch 150/300\n",
      "57/57 [==============================] - 0s 347us/step - loss: 0.5991 - acc: 0.7193\n",
      "Epoch 151/300\n",
      "57/57 [==============================] - 0s 249us/step - loss: 0.5974 - acc: 0.7193\n",
      "Epoch 152/300\n",
      "57/57 [==============================] - 0s 239us/step - loss: 0.5973 - acc: 0.7368\n",
      "Epoch 153/300\n",
      "57/57 [==============================] - 0s 307us/step - loss: 0.5964 - acc: 0.7544\n",
      "Epoch 154/300\n",
      "57/57 [==============================] - 0s 255us/step - loss: 0.5959 - acc: 0.7193\n",
      "Epoch 155/300\n",
      "57/57 [==============================] - 0s 201us/step - loss: 0.5959 - acc: 0.7193\n",
      "Epoch 156/300\n",
      "57/57 [==============================] - 0s 247us/step - loss: 0.5945 - acc: 0.7193\n",
      "Epoch 157/300\n",
      "57/57 [==============================] - 0s 295us/step - loss: 0.5938 - acc: 0.7193\n",
      "Epoch 158/300\n",
      "57/57 [==============================] - 0s 247us/step - loss: 0.5937 - acc: 0.7193\n",
      "Epoch 159/300\n",
      "57/57 [==============================] - 0s 276us/step - loss: 0.5938 - acc: 0.7193\n",
      "Epoch 160/300\n",
      "57/57 [==============================] - 0s 226us/step - loss: 0.5921 - acc: 0.7193\n",
      "Epoch 161/300\n",
      "57/57 [==============================] - 0s 375us/step - loss: 0.5926 - acc: 0.7193\n",
      "Epoch 162/300\n",
      "57/57 [==============================] - 0s 205us/step - loss: 0.5920 - acc: 0.7193\n",
      "Epoch 163/300\n",
      "57/57 [==============================] - 0s 245us/step - loss: 0.5913 - acc: 0.7368\n",
      "Epoch 164/300\n",
      "57/57 [==============================] - 0s 285us/step - loss: 0.5904 - acc: 0.7368\n",
      "Epoch 165/300\n",
      "57/57 [==============================] - 0s 355us/step - loss: 0.5902 - acc: 0.7193\n",
      "Epoch 166/300\n",
      "57/57 [==============================] - 0s 287us/step - loss: 0.5897 - acc: 0.7018\n",
      "Epoch 167/300\n",
      "57/57 [==============================] - 0s 235us/step - loss: 0.5887 - acc: 0.7193\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 259us/step - loss: 0.5887 - acc: 0.7018\n",
      "Epoch 169/300\n",
      "57/57 [==============================] - 0s 305us/step - loss: 0.5876 - acc: 0.7544\n",
      "Epoch 170/300\n",
      "57/57 [==============================] - 0s 238us/step - loss: 0.5885 - acc: 0.7018\n",
      "Epoch 171/300\n",
      "57/57 [==============================] - 0s 227us/step - loss: 0.5877 - acc: 0.7193\n",
      "Epoch 172/300\n",
      "57/57 [==============================] - 0s 282us/step - loss: 0.5867 - acc: 0.7544\n",
      "Epoch 173/300\n",
      "57/57 [==============================] - 0s 284us/step - loss: 0.5860 - acc: 0.7544\n",
      "Epoch 174/300\n",
      "57/57 [==============================] - 0s 247us/step - loss: 0.5859 - acc: 0.7368\n",
      "Epoch 175/300\n",
      "57/57 [==============================] - 0s 191us/step - loss: 0.5849 - acc: 0.7368\n",
      "Epoch 176/300\n",
      "57/57 [==============================] - 0s 188us/step - loss: 0.5843 - acc: 0.7193\n",
      "Epoch 177/300\n",
      "57/57 [==============================] - 0s 222us/step - loss: 0.5846 - acc: 0.7193\n",
      "Epoch 178/300\n",
      "57/57 [==============================] - 0s 184us/step - loss: 0.5834 - acc: 0.7368\n",
      "Epoch 179/300\n",
      "57/57 [==============================] - 0s 502us/step - loss: 0.5832 - acc: 0.7193\n",
      "Epoch 180/300\n",
      "57/57 [==============================] - 0s 321us/step - loss: 0.5837 - acc: 0.7193\n",
      "Epoch 181/300\n",
      "57/57 [==============================] - 0s 175us/step - loss: 0.5821 - acc: 0.7193\n",
      "Epoch 182/300\n",
      "57/57 [==============================] - 0s 244us/step - loss: 0.5820 - acc: 0.7193\n",
      "Epoch 183/300\n",
      "57/57 [==============================] - 0s 347us/step - loss: 0.5810 - acc: 0.7193\n",
      "Epoch 184/300\n",
      "57/57 [==============================] - 0s 208us/step - loss: 0.5816 - acc: 0.7193\n",
      "Epoch 185/300\n",
      "57/57 [==============================] - 0s 242us/step - loss: 0.5803 - acc: 0.7193\n",
      "Epoch 186/300\n",
      "57/57 [==============================] - 0s 325us/step - loss: 0.5808 - acc: 0.7368\n",
      "Epoch 187/300\n",
      "57/57 [==============================] - 0s 265us/step - loss: 0.5795 - acc: 0.7368\n",
      "Epoch 188/300\n",
      "57/57 [==============================] - 0s 228us/step - loss: 0.5799 - acc: 0.7193\n",
      "Epoch 189/300\n",
      "57/57 [==============================] - 0s 297us/step - loss: 0.5798 - acc: 0.7368\n",
      "Epoch 190/300\n",
      "57/57 [==============================] - 0s 268us/step - loss: 0.5787 - acc: 0.7193\n",
      "Epoch 191/300\n",
      "57/57 [==============================] - 0s 230us/step - loss: 0.5789 - acc: 0.6842\n",
      "Epoch 192/300\n",
      "57/57 [==============================] - 0s 286us/step - loss: 0.5778 - acc: 0.7193\n",
      "Epoch 193/300\n",
      "57/57 [==============================] - 0s 283us/step - loss: 0.5784 - acc: 0.7193\n",
      "Epoch 194/300\n",
      "57/57 [==============================] - 0s 199us/step - loss: 0.5774 - acc: 0.7368\n",
      "Epoch 195/300\n",
      "57/57 [==============================] - 0s 241us/step - loss: 0.5774 - acc: 0.7368\n",
      "Epoch 196/300\n",
      "57/57 [==============================] - 0s 343us/step - loss: 0.5764 - acc: 0.7544\n",
      "Epoch 197/300\n",
      "57/57 [==============================] - 0s 278us/step - loss: 0.5769 - acc: 0.7368\n",
      "Epoch 198/300\n",
      "57/57 [==============================] - 0s 210us/step - loss: 0.5759 - acc: 0.7368\n",
      "Epoch 199/300\n",
      "57/57 [==============================] - 0s 291us/step - loss: 0.5764 - acc: 0.7193\n",
      "Epoch 200/300\n",
      "57/57 [==============================] - 0s 257us/step - loss: 0.5759 - acc: 0.7193\n",
      "Epoch 201/300\n",
      "57/57 [==============================] - 0s 272us/step - loss: 0.5757 - acc: 0.7193\n",
      "Epoch 202/300\n",
      "57/57 [==============================] - 0s 283us/step - loss: 0.5742 - acc: 0.7544\n",
      "Epoch 203/300\n",
      "57/57 [==============================] - 0s 221us/step - loss: 0.5742 - acc: 0.7368\n",
      "Epoch 204/300\n",
      "57/57 [==============================] - 0s 208us/step - loss: 0.5739 - acc: 0.7193\n",
      "Epoch 205/300\n",
      "57/57 [==============================] - 0s 395us/step - loss: 0.5740 - acc: 0.7368\n",
      "Epoch 206/300\n",
      "57/57 [==============================] - 0s 252us/step - loss: 0.5730 - acc: 0.7368\n",
      "Epoch 207/300\n",
      "57/57 [==============================] - 0s 180us/step - loss: 0.5743 - acc: 0.7018\n",
      "Epoch 208/300\n",
      "57/57 [==============================] - 0s 204us/step - loss: 0.5732 - acc: 0.7368\n",
      "Epoch 209/300\n",
      "57/57 [==============================] - 0s 300us/step - loss: 0.5728 - acc: 0.7368\n",
      "Epoch 210/300\n",
      "57/57 [==============================] - 0s 206us/step - loss: 0.5723 - acc: 0.7368\n",
      "Epoch 211/300\n",
      "57/57 [==============================] - 0s 237us/step - loss: 0.5718 - acc: 0.7368\n",
      "Epoch 212/300\n",
      "57/57 [==============================] - 0s 185us/step - loss: 0.5714 - acc: 0.7368\n",
      "Epoch 213/300\n",
      "57/57 [==============================] - 0s 191us/step - loss: 0.5713 - acc: 0.7368\n",
      "Epoch 214/300\n",
      "57/57 [==============================] - 0s 359us/step - loss: 0.5713 - acc: 0.7368\n",
      "Epoch 215/300\n",
      "57/57 [==============================] - 0s 218us/step - loss: 0.5707 - acc: 0.7193\n",
      "Epoch 216/300\n",
      "57/57 [==============================] - 0s 254us/step - loss: 0.5702 - acc: 0.7544\n",
      "Epoch 217/300\n",
      "57/57 [==============================] - 0s 270us/step - loss: 0.5706 - acc: 0.7368\n",
      "Epoch 218/300\n",
      "57/57 [==============================] - 0s 272us/step - loss: 0.5699 - acc: 0.7368\n",
      "Epoch 219/300\n",
      "57/57 [==============================] - 0s 232us/step - loss: 0.5706 - acc: 0.7193\n",
      "Epoch 220/300\n",
      "57/57 [==============================] - 0s 218us/step - loss: 0.5689 - acc: 0.7193\n",
      "Epoch 221/300\n",
      "57/57 [==============================] - 0s 249us/step - loss: 0.5693 - acc: 0.7368\n",
      "Epoch 222/300\n",
      "57/57 [==============================] - 0s 331us/step - loss: 0.5695 - acc: 0.7368\n",
      "Epoch 223/300\n",
      "57/57 [==============================] - 0s 294us/step - loss: 0.5683 - acc: 0.7544\n",
      "Epoch 224/300\n",
      "57/57 [==============================] - 0s 216us/step - loss: 0.5681 - acc: 0.7193\n",
      "Epoch 225/300\n",
      "57/57 [==============================] - 0s 312us/step - loss: 0.5685 - acc: 0.7018\n",
      "Epoch 226/300\n",
      "57/57 [==============================] - 0s 281us/step - loss: 0.5672 - acc: 0.7544\n",
      "Epoch 227/300\n",
      "57/57 [==============================] - 0s 212us/step - loss: 0.5681 - acc: 0.7193\n",
      "Epoch 228/300\n",
      "57/57 [==============================] - 0s 237us/step - loss: 0.5670 - acc: 0.7193\n",
      "Epoch 229/300\n",
      "57/57 [==============================] - 0s 307us/step - loss: 0.5679 - acc: 0.7193\n",
      "Epoch 230/300\n",
      "57/57 [==============================] - 0s 267us/step - loss: 0.5673 - acc: 0.7193\n",
      "Epoch 231/300\n",
      "57/57 [==============================] - 0s 261us/step - loss: 0.5679 - acc: 0.7368\n",
      "Epoch 232/300\n",
      "57/57 [==============================] - 0s 268us/step - loss: 0.5674 - acc: 0.7193\n",
      "Epoch 233/300\n",
      "57/57 [==============================] - 0s 290us/step - loss: 0.5661 - acc: 0.7368\n",
      "Epoch 234/300\n",
      "57/57 [==============================] - 0s 234us/step - loss: 0.5666 - acc: 0.7544\n",
      "Epoch 235/300\n",
      "57/57 [==============================] - 0s 248us/step - loss: 0.5661 - acc: 0.7193\n",
      "Epoch 236/300\n",
      "57/57 [==============================] - 0s 263us/step - loss: 0.5659 - acc: 0.7193\n",
      "Epoch 237/300\n",
      "57/57 [==============================] - 0s 293us/step - loss: 0.5665 - acc: 0.7193\n",
      "Epoch 238/300\n",
      "57/57 [==============================] - 0s 239us/step - loss: 0.5661 - acc: 0.7193\n",
      "Epoch 239/300\n",
      "57/57 [==============================] - 0s 295us/step - loss: 0.5650 - acc: 0.7193\n",
      "Epoch 240/300\n",
      "57/57 [==============================] - 0s 229us/step - loss: 0.5649 - acc: 0.7193\n",
      "Epoch 241/300\n",
      "57/57 [==============================] - 0s 192us/step - loss: 0.5671 - acc: 0.7018\n",
      "Epoch 242/300\n",
      "57/57 [==============================] - 0s 239us/step - loss: 0.5650 - acc: 0.7193\n",
      "Epoch 243/300\n",
      "57/57 [==============================] - 0s 339us/step - loss: 0.5650 - acc: 0.7544\n",
      "Epoch 244/300\n",
      "57/57 [==============================] - 0s 276us/step - loss: 0.5642 - acc: 0.7193\n",
      "Epoch 245/300\n",
      "57/57 [==============================] - 0s 217us/step - loss: 0.5649 - acc: 0.7193\n",
      "Epoch 246/300\n",
      "57/57 [==============================] - 0s 262us/step - loss: 0.5649 - acc: 0.7193\n",
      "Epoch 247/300\n",
      "57/57 [==============================] - 0s 274us/step - loss: 0.5638 - acc: 0.7368\n",
      "Epoch 248/300\n",
      "57/57 [==============================] - 0s 237us/step - loss: 0.5633 - acc: 0.7544\n",
      "Epoch 249/300\n",
      "57/57 [==============================] - 0s 241us/step - loss: 0.5632 - acc: 0.7193\n",
      "Epoch 250/300\n",
      "57/57 [==============================] - 0s 304us/step - loss: 0.5635 - acc: 0.7544\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 273us/step - loss: 0.5627 - acc: 0.7193\n",
      "Epoch 252/300\n",
      "57/57 [==============================] - 0s 219us/step - loss: 0.5634 - acc: 0.7193\n",
      "Epoch 253/300\n",
      "57/57 [==============================] - 0s 295us/step - loss: 0.5642 - acc: 0.7368\n",
      "Epoch 254/300\n",
      "57/57 [==============================] - 0s 291us/step - loss: 0.5625 - acc: 0.7368\n",
      "Epoch 255/300\n",
      "57/57 [==============================] - 0s 236us/step - loss: 0.5623 - acc: 0.7368\n",
      "Epoch 256/300\n",
      "57/57 [==============================] - 0s 225us/step - loss: 0.5634 - acc: 0.7368\n",
      "Epoch 257/300\n",
      "57/57 [==============================] - 0s 215us/step - loss: 0.5621 - acc: 0.7193\n",
      "Epoch 258/300\n",
      "57/57 [==============================] - 0s 267us/step - loss: 0.5624 - acc: 0.7368\n",
      "Epoch 259/300\n",
      "57/57 [==============================] - 0s 460us/step - loss: 0.5628 - acc: 0.7368\n",
      "Epoch 260/300\n",
      "57/57 [==============================] - 0s 369us/step - loss: 0.5614 - acc: 0.7544\n",
      "Epoch 261/300\n",
      "57/57 [==============================] - 0s 210us/step - loss: 0.5620 - acc: 0.7193\n",
      "Epoch 262/300\n",
      "57/57 [==============================] - 0s 211us/step - loss: 0.5618 - acc: 0.7193\n",
      "Epoch 263/300\n",
      "57/57 [==============================] - 0s 363us/step - loss: 0.5609 - acc: 0.7368\n",
      "Epoch 264/300\n",
      "57/57 [==============================] - 0s 304us/step - loss: 0.5610 - acc: 0.7368\n",
      "Epoch 265/300\n",
      "57/57 [==============================] - 0s 278us/step - loss: 0.5609 - acc: 0.7368\n",
      "Epoch 266/300\n",
      "57/57 [==============================] - 0s 275us/step - loss: 0.5605 - acc: 0.7368\n",
      "Epoch 267/300\n",
      "57/57 [==============================] - 0s 277us/step - loss: 0.5601 - acc: 0.7544\n",
      "Epoch 268/300\n",
      "57/57 [==============================] - 0s 260us/step - loss: 0.5612 - acc: 0.7368\n",
      "Epoch 269/300\n",
      "57/57 [==============================] - 0s 254us/step - loss: 0.5598 - acc: 0.7193\n",
      "Epoch 270/300\n",
      "57/57 [==============================] - 0s 248us/step - loss: 0.5598 - acc: 0.7368\n",
      "Epoch 271/300\n",
      "57/57 [==============================] - 0s 251us/step - loss: 0.5601 - acc: 0.7193\n",
      "Epoch 272/300\n",
      "57/57 [==============================] - 0s 257us/step - loss: 0.5607 - acc: 0.7193\n",
      "Epoch 273/300\n",
      "57/57 [==============================] - 0s 224us/step - loss: 0.5606 - acc: 0.7544\n",
      "Epoch 274/300\n",
      "57/57 [==============================] - 0s 294us/step - loss: 0.5598 - acc: 0.7544\n",
      "Epoch 275/300\n",
      "57/57 [==============================] - 0s 223us/step - loss: 0.5598 - acc: 0.7368\n",
      "Epoch 276/300\n",
      "57/57 [==============================] - 0s 237us/step - loss: 0.5590 - acc: 0.7544\n",
      "Epoch 277/300\n",
      "57/57 [==============================] - 0s 246us/step - loss: 0.5593 - acc: 0.7193\n",
      "Epoch 278/300\n",
      "57/57 [==============================] - 0s 299us/step - loss: 0.5585 - acc: 0.7544\n",
      "Epoch 279/300\n",
      "57/57 [==============================] - 0s 299us/step - loss: 0.5590 - acc: 0.7368\n",
      "Epoch 280/300\n",
      "57/57 [==============================] - 0s 396us/step - loss: 0.5594 - acc: 0.7193\n",
      "Epoch 281/300\n",
      "57/57 [==============================] - 0s 260us/step - loss: 0.5593 - acc: 0.7368\n",
      "Epoch 282/300\n",
      "57/57 [==============================] - 0s 330us/step - loss: 0.5579 - acc: 0.7544\n",
      "Epoch 283/300\n",
      "57/57 [==============================] - 0s 276us/step - loss: 0.5595 - acc: 0.7368\n",
      "Epoch 284/300\n",
      "57/57 [==============================] - 0s 263us/step - loss: 0.5576 - acc: 0.7368\n",
      "Epoch 285/300\n",
      "57/57 [==============================] - 0s 277us/step - loss: 0.5592 - acc: 0.7368\n",
      "Epoch 286/300\n",
      "57/57 [==============================] - 0s 229us/step - loss: 0.5582 - acc: 0.7368\n",
      "Epoch 287/300\n",
      "57/57 [==============================] - 0s 231us/step - loss: 0.5577 - acc: 0.7368\n",
      "Epoch 288/300\n",
      "57/57 [==============================] - 0s 288us/step - loss: 0.5593 - acc: 0.7368\n",
      "Epoch 289/300\n",
      "57/57 [==============================] - 0s 202us/step - loss: 0.5572 - acc: 0.7368\n",
      "Epoch 290/300\n",
      "57/57 [==============================] - 0s 276us/step - loss: 0.5582 - acc: 0.7544\n",
      "Epoch 291/300\n",
      "57/57 [==============================] - 0s 258us/step - loss: 0.5579 - acc: 0.7368\n",
      "Epoch 292/300\n",
      "57/57 [==============================] - 0s 239us/step - loss: 0.5569 - acc: 0.7544\n",
      "Epoch 293/300\n",
      "57/57 [==============================] - 0s 242us/step - loss: 0.5575 - acc: 0.7368\n",
      "Epoch 294/300\n",
      "57/57 [==============================] - 0s 285us/step - loss: 0.5573 - acc: 0.7544\n",
      "Epoch 295/300\n",
      "57/57 [==============================] - 0s 237us/step - loss: 0.5581 - acc: 0.7193\n",
      "Epoch 296/300\n",
      "57/57 [==============================] - 0s 300us/step - loss: 0.5567 - acc: 0.7368\n",
      "Epoch 297/300\n",
      "57/57 [==============================] - 0s 185us/step - loss: 0.5563 - acc: 0.7193\n",
      "Epoch 298/300\n",
      "57/57 [==============================] - 0s 300us/step - loss: 0.5572 - acc: 0.7368\n",
      "Epoch 299/300\n",
      "57/57 [==============================] - 0s 254us/step - loss: 0.5571 - acc: 0.7193\n",
      "Epoch 300/300\n",
      "57/57 [==============================] - 0s 214us/step - loss: 0.5566 - acc: 0.7544\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=300, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 770us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6115584606077613, 0.7317073170731707]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.evaluate(X_test, y_test, batch_size=10) #returns loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  4]\n",
      " [ 7 15]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, model.predict(X_test)>0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0cc370b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"acc\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"loss\", \"acc\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9124464]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Probability that first movie in final match up will win:\n",
    "model.predict(X_final) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "A much simpler approach a little more robust against sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.as_matrix()\n",
    "y_train = np.squeeze(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6829268292682927"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the accuracy on the test set -- seems to be a bit worse than NN\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  6]\n",
      " [ 7 15]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, model.predict(X_test)>0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return_1</th>\n",
       "      <th>popularity_1</th>\n",
       "      <th>vote_count_1</th>\n",
       "      <th>vote_average_1</th>\n",
       "      <th>return_2</th>\n",
       "      <th>popularity_2</th>\n",
       "      <th>vote_count_2</th>\n",
       "      <th>vote_average_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.258803</td>\n",
       "      <td>0.616013</td>\n",
       "      <td>0.845455</td>\n",
       "      <td>7.791670e-07</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.14784</td>\n",
       "      <td>0.790909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   return_1  popularity_1  vote_count_1  vote_average_1      return_2  \\\n",
       "0  0.000002      0.258803      0.616013        0.845455  7.791670e-07   \n",
       "\n",
       "   popularity_2  vote_count_2  vote_average_2  \n",
       "0      0.024822       0.14784        0.790909  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33984156, 0.66015844]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability of 0, and probability of 1\n",
    "#in other words, probability fargo wins, probability pulp fiction wins\n",
    "model.predict_proba(X_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
